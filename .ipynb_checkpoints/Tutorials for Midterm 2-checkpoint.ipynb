{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############################################################\n",
    "##  In this tutorial, we are going to learn to assess the \n",
    "## goodnes of fits of models and to compare models.\n",
    "## In the class, we are going to learn do this both with classical statistics (Anova) and\n",
    "## with modern cross-validation approaches (next week)\n",
    "\n",
    "# We are now going to practice doing the statistics for linear models using the F-statistic.\n",
    "library(car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " Remember the job prestige data has a mixture of numeric predictors (income, education, women) and factors (group)\n",
    "\n",
    "# Always take a peak at the data and look at the sample size\n",
    "head(Prestige)\n",
    "nrow(Prestige)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Always visualize your data\n",
    "scatterplotMatrix(~ prestige + log2(income) + education + women | type, data=Prestige, by.group=TRUE, id.n=0,\n",
    "                  smooth=FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our favorite model is an ANOCOVA where type as a factor and education and log(income) as covariates  \n",
    "prestige.mod <- lm(prestige ~ education*type + log2(income)*type,\n",
    "                      data=Prestige)\n",
    "summary(prestige.mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "# Type I and II ANOVA\n",
    "#######################################\n",
    "\n",
    "# The anova command (fom the stats library) shows sequential F values. This hypothesis\n",
    "# testing is sometimes called a Type I anova. In a Type I ANOVA, also called a sequential\n",
    "# ANOVA, a series of models are fit, and the *difference* in sum-of-square error between\n",
    "# each model is reported in the summary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Examine the table that's printed out after\n",
    "# running a sequential ANOVA:\n",
    "\n",
    "anova(prestige.mod)\n",
    "#This F stat is a comparison between the mean model (null model with only intercept) and the full model\n",
    "\n",
    "# The \"Sum Sq\" column in the table above is *difference* in model sum-of-squares (SSerr) for several\n",
    "# different models. The first row is a model that just predicts prestige from education,\n",
    "# which can be written (prestige ~ education). The \"Sum Sq\" column for this row shows\n",
    "# the sum-of-squares error of a model that just uses the overall mean, also called SStotal,\n",
    "# minus the sum-of-squares error of the model prestige ~ education.\n",
    "# Likewise, the second row shows the difference in the sum-of-squares error between\n",
    "# a the model prestige ~ education and the model prestige ~ education + type.\n",
    "# Check out section 4.4.3 of the blue Fox book for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Is this true?\n",
    "\n",
    "meanmod = lm(prestige ~1, data=Prestige)\n",
    "edmod = lm(prestige ~ education, data=Prestige)\n",
    "SSEmeanmod = sum(meanmod$residuals^2)\n",
    "SSEedmod = sum(edmod$residuals^2)\n",
    "SSEmeanmod-SSEedmod\n",
    "#21608 this is off because we didn't get rid of NAs first\n",
    "\n",
    "#so yes, this does appear to be correct -- chack again using the same df\n",
    "Prestige2 = na.omit(Prestige)\n",
    "\n",
    "meanmod = lm(prestige ~1, data=Prestige2)\n",
    "edmod = lm(prestige ~ education, data=Prestige2)\n",
    "SSEmeanmod = sum(meanmod$residuals^2)\n",
    "SSEedmod = sum(edmod$residuals^2)\n",
    "SSEmeanmod-SSEedmod\n",
    "#21282 this is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#http://stat.ethz.ch/R-manual/R-patched/library/stats/html/anova.lm.html\n",
    "\n",
    "#This is slightly off from 21282, the result from anova()\n",
    "\n",
    "# Sequential F values are \"out-of-favor\" ... It is better to look at type II anovas.  The function\n",
    "# Anova() - with a capital A (from the car library) performs these tests.  In these tests, a model\n",
    "# that includes all regressors is compared to a model that includes all other regressors but one. (It\n",
    "# is a bit more complicated when interactions are involved)\n",
    "#\n",
    "# For more information on Type I/II/III ANOVA, check out sec 4.4.4 of blue Fox or this explanation:\n",
    "#    https://mcfromnz.wordpress.com/2011/03/02/anova-type-iiiiii-ss-explained/\n",
    "prestige.mod <- lm(prestige ~ education*type + log2(income)*type, data=Prestige2)\n",
    "\n",
    "Anova(prestige.mod, type=\"II\")\n",
    "#Anova Table (Type II tests)\n",
    "\n",
    "#Response: prestige\n",
    "#                    Sum Sq Df F value    Pr(>F)    \n",
    "#education         1209.3    1 29.4446 4.912e-07 ***\n",
    "  #type               469.1  2  5.7103  0.004642 ** \n",
    "  #log2(income)      1690.8  1  41.1670 6.589e-09 ***\n",
    "  #education:type     178.8  2  2.1762  0.119474    \n",
    "#type:log2(income)  290.3    2  3.5344  0.033338 *  \n",
    "  #Residuals         3655.4 89 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# An ANOVA procedure can be used to test the significance of any two models (two alternative hypotheses)\n",
    "# Here we'll compare the model prestige ~ education + log2(income) + type to a model with only\n",
    "# an intercept term\n",
    "prestige.mod.1 <- lm(prestige ~ education + log2(income) + type, data=na.omit(Prestige)) # full model\n",
    "prestige.mod.0 <- update(prestige.mod.1, . ~ 1) # intercept only\n",
    "anova(prestige.mod.0, prestige.mod.1) # compare models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "# EXERCISE 1\n",
    "#\n",
    "# Where else would you find the same F value as the one in the anova command above? Check to see if it is the same. Hint: the F value\n",
    "# output of ANOVA is for comparison of the model prestige ~ education + log2(income) + type to a\n",
    "# model with only an intercept. What do you know about the output of summary(prestige.mod.1)?\n",
    "#########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary(prestige.mod.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prestige.mod.0inc <- update(prestige.mod.1, . ~ . - log2(income))\n",
    "anova(prestige.mod.0inc, prestige.mod.1) # compare models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "# EXERCISE 2\n",
    "#\n",
    "# What does this F value correspond to?  Give two other ways of\n",
    "# obtaining it. One way is to explore the output of a Type II ANOVA using\n",
    "# on prestige.mod.1. Which model comparison does the matching F value\n",
    "# correspond to?\n",
    "#########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Anova(prestige.mod.1)\n",
    "#corresponds to the second F value in this Type II Anova\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# More generally you can use the anova command to compare two nested models\n",
    "prestige.mod.1 <- lm(prestige ~ education + log2(income) + type,\n",
    "    data=na.omit(Prestige)) # full model\n",
    "prestige.mod.ed  <- lm(prestige ~ education, data=na.omit(Prestige))\n",
    "(prestige.mod.ed.sum <- summary(prestige.mod.ed))\n",
    "\n",
    "anova(prestige.mod.ed, prestige.mod.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################  Done with Classical Model Validation #########\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(car)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############################################################\n",
    "##  In this tutorial, we are going to learn to assess the \n",
    "## goodnes of fits of models and to compare models\n",
    "## with modern cross-validation approaches.\n",
    "\n",
    "# We are now going to practice doing the statistics for linear models using the F-statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remember the job prestige data has a mixture of numeric predictors (income, education, women) and factors (group)\n",
    "\n",
    "# Always take a peak at the data and look at the sample size\n",
    "head(Prestige)\n",
    "nrow(Prestige)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Always visualize your data\n",
    "scatterplotMatrix(~ prestige + log2(income) + education + women | type, data=Prestige, by.group=TRUE, id.n=0,\n",
    "                  smooth=FALSE, col=gray(c(0,0.5,0.7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some of the rows have missing data.  Since we are going to compare models using\n",
    "# our own functions, we are going to eliminate rows with NA.\n",
    "is.na(Prestige)\n",
    "Prestige.clean <- Prestige[rowSums(is.na(Prestige)) == 0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our favorite model is an ANOCOVA where type as a factor and education and log(income) as covariates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prestige.mod.full <- lm(prestige ~ education*type + log2(income)*type,\n",
    "                      data=Prestige.clean)\n",
    "(prestige.mod.full.sum <- summary(prestige.mod.full))\n",
    "\n",
    "prestige.mod.ed <- lm(prestige ~ education, data=Prestige.clean)\n",
    "(prestige.mod.ed.sum <- summary(prestige.mod.ed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aov.results <- anova(prestige.mod.ed, prestige.mod.full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The partial R2\n",
    "(R2.ed.vs.full <- 1 - (aov.results$RSS[2]/aov.results$Res.Df[2])/(aov.results$RSS[1]/aov.results$Res.Df[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################  Model Validation with Resampling #########\n",
    "# Cross-validation with bootstrap estimates of R2.\n",
    "# We are now going to perform a 10-fold cross validation on the prestige\n",
    "# data frame to get our own value of R2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First we randomly shuffle the data and omit na rows.\n",
    "n.folds <- 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#break up the first ten rows etc just in case there is something going on here\n",
    "my.Prestige <-na.omit(Prestige[sample(nrow(Prestige)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next, we create 10 equally size folds\n",
    "folds <- cut(seq(1,nrow(my.Prestige)),breaks=n.folds,labels=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 - Cross validated R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################################\n",
    "#   Exercise 1.  Complete the following loop to get n.folds value\n",
    "# of cross validated R2 (one for each fold) for the full model and the model with Education only compared to\n",
    "# the zeroth order model and the full model compared to the education model.  \n",
    "# Compare the mean of those cv-R2 to the adjusted R2 you got in the summary\n",
    "# or to the adjusted R2 you used to calculate the error decrease\n",
    "# going from model 1 to model 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make space for your arrays\n",
    "R2.cv.full <- array(data=0, dim = n.folds)\n",
    "R2.cv.ed <- array(data=0, dim = n.folds)\n",
    "R2.cv.ed.vs.full <- array(data=0, dim=n.folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Perform n.folds fold cross validation\n",
    "for(i in 1:n.folds){\n",
    "    #Segement your data by fold using the which() function \n",
    "    testIndexes <- which(folds==i,arr.ind=TRUE) #gives all indices where folds = i\n",
    "    testData <- my.Prestige[testIndexes, ]\n",
    "    trainData <- my.Prestige[-testIndexes, ]\n",
    "    \n",
    "    #Your code here\n",
    "    # Fit the two models \n",
    "    \n",
    "    #full model\n",
    "    prestige.mod.full <- lm(prestige ~ education*type + log2(income)*type,data=trainData)\n",
    "    #education only model\n",
    "    prestige.mod.ed <- lm(prestige ~ education, data=trainData)\n",
    "    #null model\n",
    "    prestige.mean.train = mean(trainData$prestige)\n",
    "    ######################  Model Validation with Resampling #########\n",
    "\n",
    "    # Get predictions\n",
    "    prestige_hat_full = predict.lm(prestige.mod.full, testData)\n",
    "    prestige_hat_ed = predict.lm(prestige.mod.ed, testData)\n",
    "\n",
    "    # Calculate cv R2.\n",
    "    ss2 = sum((testData$prestige - prestige_hat_full)^2)\n",
    "    ss1 = sum((testData$prestige - prestige_hat_ed)^2) #ss1 will be from the less complex model, in this case ed\n",
    "    ss0 = sum((testData$prestige - prestige.mean.train)^2)\n",
    "    \n",
    "    R2.cv.full[i] = 1-ss2/ss0\n",
    "    R2.cv.ed[i] = 1 - ss1/ss0\n",
    "    R2.cv.ed.vs.full[i] = 1 - ss2/ss1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# More summary code here\n",
    "#mean(R2.cv.ed) #.73\n",
    "#(prestige.mod.ed.sum) #.75\n",
    "sprintf('Ed Model: R2 cv = %.2f +- %.3f vs R2 adj= %.2f', mean(R2.cv.ed), sd(R2.cv.ed), prestige.mod.ed.sum$adj.r.squared)\n",
    "\n",
    "#mean(R2.cv.ed.vs.full) #.36\n",
    "#R2.ed.vs.full #.44\n",
    "sprintf('Compared Models: R2 cv = %.2f +- %.3f vs R2 adj= %.2f', mean(R2.cv.ed.vs.full), sd(R2.cv.ed.vs.full), R2.ed.vs.full)\n",
    "\n",
    "#mean(R2.cv.full) #.84\n",
    "#prestige.mod.full.sum #.86\n",
    "sprintf('Full Model: R2 cv = %.2f +- %.3f vs R2 adj= %.2f', mean(R2.cv.full), sd(R2.cv.full), prestige.mod.full.sum$adj.r.squared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this lets you get the mean of a statistic, as well as the standard error of that statistic (ie sd in this case)\n",
    "\n",
    "#IF R2 cv is different from 0, then you know. Use your standard error - 2*standard error (ie standard deviation) is 5%. So take the R2 cv and subtract sd(R2cv)*2 (remember sd(R2cv)=SE)\n",
    "\n",
    "#Rule of thumb -- need a minimum of 10 df on your testing df -- ie if you are training one with 5 you need 50 \n",
    "\n",
    "#This is another way to visualize these statistics -- it lets you see the 95% confidence interval and mean of your cross validated R2 estimates easily\n",
    "#if the tail hit 0 then that would be bad!\n",
    "boxplot(cbind(R2.cv.full, R2.cv.ed, R2.cv.ed.vs.full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional example - permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "# Permutation test example from Text book. \n",
    "###################################\n",
    "# Our second example is the permutation test from the book.\n",
    "# In this case we are interrested in determining whether a model for salary prediction fitted on men works for women as well.\n",
    "library(car)\n",
    "set.seed(12345) # to reproduce results in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Let's look at the data format\n",
    "some(Salaries)\n",
    "nrow(Salaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# let's relevel the factor rank\n",
    "Salaries$rank <- relevel(Salaries$rank, ref=\"AsstProf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Making a table to see how many subjects in each category\n",
    "# xtabs make a table and ftable \"flattens\" the table\n",
    "ftable(x1 <- xtabs(~ discipline + rank + sex, data=Salaries))\n",
    "round(100*ftable(prop.table(x1, margin=c(1, 2))), 1) # % m and f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# We are plotting the data\n",
    "library(lattice)\n",
    "xyplot(salary ~ yrs.since.phd | discipline:rank, group=sex,\n",
    "  data=Salaries, type=c(\"g\", \"p\", \"r\"), auto.key=TRUE)\n",
    "\n",
    "bwplot(salary ~ discipline:sex | rank, data=Salaries,\n",
    "    scales=list(rot=90), layout=c(3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate a model for Males only\n",
    "fselector <- Salaries$sex == \"Female\" # TRUE for females\n",
    "salmod <- lm(salary ~ rank*discipline + yrs.since.phd, data=Salaries,\n",
    "    subset=!fselector) # regression for males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predictions for females:\n",
    "femalePreds <- predict(salmod, newdata=Salaries[fselector, ])\n",
    "(meanDiff <- mean(Salaries$salary[fselector] - femalePreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's do a bootstrap to see how often we could get this result\n",
    "set.seed(8141976) # for reproducibility\n",
    "fnumber <- sum(fselector) # number of females\n",
    "n <- length(fselector) # number of observations\n",
    "B <- 2 # number of replications\n",
    "simDiff <- numeric(B) # initialize vector with B entries\n",
    "for (j in 1:B){\n",
    "    sel <- sample(1:n, fnumber) # random sample of nominated 'females'\n",
    "    m2 <- update(salmod, subset=-sel) # refit regression model\n",
    "    simDiff[j] <- mean(Salaries$salary[sel]\n",
    "        - predict(m2, newdata=Salaries[sel, ])) # compute mean diff.\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the p-value    \n",
    "(frac <- round(sum(meanDiff > simDiff)/(1 + B), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the histogram\n",
    "hist(simDiff,\n",
    "   main=paste(\"Histogram of Simulated Mean Differences\\np-value =\",\n",
    "       frac),\n",
    "   xlab=\"Dollars\")\n",
    "abline(v=meanDiff, lty=\"dashed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional example - overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "# Our last example examines overfitting.\n",
    "#######################################\n",
    "\n",
    "# We are now going to do an example with data from the Theunissen lab.\n",
    "# In the data, we quantify the \"timbre\" of a musical instrument with the timbre\n",
    "# column, and various acoustic features of the sound in the columns labeled\n",
    "# sound.1, sound.2, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in file(file, \"rt\"):\n",
      "\"cannot open file 'mds1PCA40.txt': No such file or directory\""
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in file(file, \"rt\"): cannot open the connection\n",
     "output_type": "error",
     "traceback": [
      "Error in file(file, \"rt\"): cannot open the connection\nTraceback:\n",
      "1. read.table(\"mds1PCA40.txt\")",
      "2. file(file, \"rt\")"
     ]
    }
   ],
   "source": [
    "# First, change this path to the path where the file mds1PCA40.txt lives:\n",
    "setwd('C:/Users/William/Documents/Berkeley_Post-Bac/01 - Courses/Spring 2018 Classes/Psych 205/homework')\n",
    "\n",
    "# Then read the file and print out the number of rows\n",
    "Timbre <- read.table('mds1PCA40.txt')\n",
    "(n.inst <- nrow(Timbre))\n",
    "\n",
    "# Check out a summary of the data. It's all numerical! \n",
    "summary(Timbre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "# EXERCISE 2\n",
    "# Use Scatter plot matrix to visualize the data.  Use only the first 3 sound features, specifically\n",
    "# sound.1, sound.2, and sound.3.\n",
    "######################################\n",
    "#for everything\n",
    "#two methods of getting it for sound 1-3\n",
    "scatterplot.matrix(Timbre[,2:4])\n",
    "scatterplotMatrix(~ sound.1 + sound.2 + sound.3, data=Timbre, by.group=TRUE, id.n=0, smooth=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameter_ct = 40\n",
    "\n",
    "Rvals <- numeric(parameter_ct)\n",
    "Rvals.adj  <- numeric(parameter_ct)\n",
    "timbre.mod <- lm(timbre ~ sound.1, data=Timbre)\n",
    "(timbre.sum <- summary(timbre.mod))\n",
    "Rvals[1] <- timbre.sum$r.squared\n",
    "sserror <- sum(timbre.mod$residual^2)\n",
    "mean.timbre <- mean(timbre.mod$model$timbre)\n",
    "sstotal <- sum((timbre.mod$model$timbre - mean.timbre)^2)\n",
    "dferror <- timbre.mod$df.residual  # n - k -1\n",
    "dftotal  <- length(timbre.mod$fitted.values)-1 # n - 1\n",
    "Rvals.adj[1]  <- 1- ((sserror/dferror)/(sstotal/dftotal))\n",
    "\n",
    "for(i in 2:40){\n",
    "  timbre.mod <- update(timbre.mod, sprintf(\". ~ . + sound.%d\", i))\n",
    "  timbre.sum <- summary(timbre.mod)\n",
    "  Rvals[i] <- timbre.sum$r.squared\n",
    "  sserror <- sum(timbre.mod$residual^2)\n",
    "  dferror <- timbre.mod$df.residual  # n - k -1\n",
    "  Rvals.adj[i]  <- 1- ((sserror/dferror)/(sstotal/dftotal))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rvals <- numeric(parameter_ct)\n",
    "#Rvals.adj  <- numeric(parameter_ct)\n",
    "#for(i in 1:parameter_ct){\n",
    "  #timbre.mod <- lm(timbre ~ [1:i], data=Timbre)\n",
    "  #(timbre.sum <- summary(timbre.mod))\n",
    "  #Rvals[i] <- timbre.sum$r.squared\n",
    "  #sserror <- sum(timbre.mod$residual^2)\n",
    "  #mean.timbre <- mean(timbre.mod$model$timbre)\n",
    "  #sstotal <- sum((timbre.mod$model$timbre - mean.timbre)^2)\n",
    "  #dferror <- timbre.mod$df.residual  # n - k -1\n",
    "  #dftotal  <- length(timbre.mod$fitted.values)-1 # n - 1\n",
    "  #Rvals.adj[i]  <- 1- ((sserror/dferror)/(sstotal/dftotal))\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#basic plot\n",
    "plot(Rvals)\n",
    "lines(Rvals.adj, col=\"red\")\n",
    "\n",
    "#nicer plot\n",
    "plot.new()\n",
    "plot(Rvals, type=\"l\", col=\"blue\", xlab=\"Number of predictors\", ylab=\"r squared\", main=\"Comparison of R2 (blue) and R2adj (red)\")\n",
    "lines(Rvals.adj, col=\"red\")\n",
    "legend(1, 1, legend=c(\"R2\", \"R2 adj\"),\n",
    "       col=c(\"blue\", \"red\"), lty=1, cex=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################\n",
    "# EXERCISE 4 \n",
    "# Calculate by \"hand\" the R-square obtained for a model with 3\n",
    "# sound parameters. Hint: You have done this on your previous tutorial. Use\n",
    "# the $residuals of the model timbre ~ sound.1 + sound.2 + sound.3.\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sound1to3 <- lm(timbre ~ sound.1 + sound.2 + sound.3, data=Timbre)\n",
    "\n",
    "summary(sound1to3)\n",
    "#Multiple R-squared:  0.7506,\tAdjusted R-squared:  0.7309 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meanmod = lm(timbre ~1, data=Timbre)\n",
    "basemod = lm(timbre ~ sound.1 + sound.2 + sound.3, data=Timbre)\n",
    "SSEmeanmod = sum(meanmod$residuals^2)\n",
    "SSEbasemod = sum(basemod$residuals^2)\n",
    "SSEmeanmod-SSEbasemod\n",
    "\n",
    "R2_model = 1 - SSEbasemod/SSEmeanmod\n",
    "\n",
    "R2_adj_model = 1 - (SSEbasemod/(42-3-1))/(SSEmeanmod/(42-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################\n",
    "# EXERCISE 5\n",
    "# Using the cross-validation example above and a model with 3 sound parameters:\n",
    "#  1) Randomly divide the sound instruments into a \"fitting\" and \"validation\" data set. (Use only one fold for simplicity)\n",
    "#  2) Fit a linear model on the \"fitting\" data set.\n",
    "#  3) Predict the timbre of the data points in the \"validation\" data set using the linear\n",
    "#     model you fit on the \"fitting\" data set, report the R2. Hint: use the predict(..) function\n",
    "#     with data = the fitting data set.\n",
    "#  4) Repeat 1-3 for models that include an increasing number of sound features. The exercise\n",
    "#     started with a model trained on 3 features, but combine the code you wrote to do 1-3 with\n",
    "#     code from exercise 3 to loop through models that increase in the number of sounds they\n",
    "#     utilize as predictors. The goal is to determine the \"generalization\" performance of each\n",
    "#     model. Generalization performance is defined here as the R2 of model predictions on the \"validation\"\n",
    "#     data set, when that model has been trained on the \"fitting\" data set.\n",
    "#\n",
    "# Suggestion: use 10 data ponts for a validation data set but note that you will then have n-10 rows\n",
    "# in your data set for fitting model parameters.\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rm(list=ls())\n",
    "library(car)\n",
    "\n",
    "# First, change this path to the path where the file mds1PCA40.txt lives:\n",
    "setwd('C:/Users/William/Documents/Berkeley_Post-Bac/01 - Courses/Spring 2018 Classes/Psych 205/homework')\n",
    "\n",
    "# Then read the file and print out the number of rows\n",
    "Timbre <- read.table('mds1PCA40.txt')\n",
    "(n.inst <- nrow(Timbre))\n",
    "\n",
    "# Check out a summary of the data. It's all numerical! \n",
    "summary(Timbre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5.1-3, My version\n",
    "test_size = 10\n",
    "cv_split = c(rep(0,nrow(Timbre)-test_size),rep(1,test_size))\n",
    "\n",
    "Timbre$cv = sample(cv_split)\n",
    "test = Timbre[Timbre$cv==1,]\n",
    "train = Timbre[Timbre$cv==0,]\n",
    "\n",
    "trainmod <- lm(timbre ~ sound.1 + sound.2 + sound.3, data=train)\n",
    "meanmod = lm(timbre ~1, data=train)\n",
    "timbre_mean = mean(train$timbre)\n",
    "\n",
    "testpreds = predict.lm(trainmod, test)\n",
    "meanpreds = predict.lm(meanmod, test)\n",
    "\n",
    "ss1 = sum((test$timbre - testpreds)^2)\n",
    "ss0 = sum((test$timbre- meanpreds)^2)\n",
    "\n",
    "R2cv = 1 - ss1/ss0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#5.1-3, class version\n",
    "#testindex = sample(1:42, replace=F)\n",
    "#test = Timbre[testindex,]\n",
    "#train = Timbre[-testindex,]\n",
    "#mod = lm(timbre~sound.1 + sound.2 + sound.3, data=train)\n",
    "#preds = predict(mod, newdata=test)\n",
    "#nullmod = mean(mod$model$timbre)\n",
    "#SSE= sum((test$timbre - preds)^2)\n",
    "#SST = sum((test$timbre - nullmod)^2)\n",
    "#R2cv = 1 - SSE/SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to find a cross validated R^2\n",
    "find_R2cv = function(train_subset, test){\n",
    "  trainmod <- lm(timbre ~ ., data=train_subset)\n",
    "  meanmod = lm(timbre ~1, data=train_subset) #this is identical to taking the mean\n",
    "  testpreds = predict.lm(trainmod, test)\n",
    "  meanpreds = predict.lm(meanmod, test)\n",
    "  \n",
    "  ss1 = sum((test$timbre - testpreds)^2)\n",
    "  ss0 = sum((test$timbre- meanpreds)^2)\n",
    "  \n",
    "  R2cv = 1 - ss1/ss0\n",
    "  return(R2cv)\n",
    "}\n",
    "\n",
    "#function to find all cross validated R^2 for a given # of params\n",
    "find_all_R2cvs = function(Timbre){\n",
    "  R2cvs = integer(40)\n",
    "  test_size = 10\n",
    "  cv_split = c(rep(0,nrow(Timbre)-test_size),rep(1,test_size)) # I think this is cleaner than using which()\n",
    "  rands = sample(cv_split)\n",
    "  test = Timbre[rands==1,]\n",
    "  train = Timbre[rands==0,]\n",
    "  for(i in 1:40){ #I don't think that the sampling should be inside the for loop. My reasoning\n",
    "    #is that the cross validated R^2 with more parameters is better compared on the same data\n",
    "    #so we are seeing just the effects of adding parameters and not adding additional\n",
    "    #noise by resampling. Later on I will run these tests many times and average across them\n",
    "    #to get a better estimate\n",
    "    #Also note that this could only go to 30, since I only have 42-10 = 32 rows for fitting my dataset on. There isn't much point to training models beyond this\n",
    "    #subset\n",
    "    keeps = 1:(i+1) #i think this is cleaner than the method used above -- it works with\n",
    "    #more types of column names\n",
    "    train_subset = subset(train, select=keeps)\n",
    "    R2cvs[i] = find_R2cv(train_subset, test)\n",
    "  }\n",
    "  return(R2cvs)\n",
    "}\n",
    "\n",
    "#this gives the answer to exercise 5-4\n",
    "#shows that at first it is terrible, gets good with just a few parameters,\n",
    "#and then gets worse and worse as it overfits more and more\n",
    "#at a certain point it is worse than a null model\n",
    "answer = find_all_R2cvs(Timbre)\n",
    "\n",
    "#this gives a more accurate answer by repeating this process a number of times\n",
    "#You can set reps much higher for fun\n",
    "reps = 100\n",
    "res1 = matrix(vector(),40,reps) #create an empty results matrix\n",
    "for(j in 1:reps){\n",
    "  res1[,j] = find_all_R2cvs(Timbre) #run this over and over, put data in results matrix\n",
    "}\n",
    "\n",
    "averages = rowMeans(res1) #get the average across rows\n",
    "\n",
    "#basic plot\n",
    "plot(averages, type='l', col='blue', main='R^2cv by # of parameters', ylab='R^2 cross validated', xlab=\"number of parameters used\", ylim=c(0,1))\n",
    "legend(1, 1, legend=c(\"R2 CV\"),\n",
    "       col=c(\"blue\"), lty=1, cex=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Method 1\n",
    "parameter_ct = 40\n",
    "\n",
    "Rvals <- numeric(parameter_ct)\n",
    "Rvals.adj  <- numeric(parameter_ct)\n",
    "timbre.mod <- lm(timbre ~ sound.1, data=Timbre)\n",
    "(timbre.sum <- summary(timbre.mod))\n",
    "Rvals[1] <- timbre.sum$r.squared\n",
    "sserror <- sum(timbre.mod$residual^2)\n",
    "mean.timbre <- mean(timbre.mod$model$timbre)\n",
    "sstotal <- sum((timbre.mod$model$timbre - mean.timbre)^2)\n",
    "dferror <- timbre.mod$df.residual  # n - k -1\n",
    "dftotal  <- length(timbre.mod$fitted.values)-1 # n - 1\n",
    "Rvals.adj[1]  <- 1- ((sserror/dferror)/(sstotal/dftotal))\n",
    "\n",
    "for(i in 2:40){\n",
    "  timbre.mod <- update(timbre.mod, sprintf(\". ~ . + sound.%d\", i))\n",
    "  timbre.sum <- summary(timbre.mod)\n",
    "  Rvals[i] <- timbre.sum$r.squared\n",
    "  sserror <- sum(timbre.mod$residual^2)\n",
    "  dferror <- timbre.mod$df.residual  # n - k -1\n",
    "  Rvals.adj[i]  <- 1- ((sserror/dferror)/(sstotal/dftotal))\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Even better plot for 5-4\n",
    "plot.new()\n",
    "plot(Rvals, type=\"l\", col=\"blue\", xlab=\"Number of predictors\", ylab=\"r squared\", main=\"Comparison of R2 (blue), R2adj (red), and R2cv (green)\")\n",
    "lines(Rvals.adj, col=\"red\")\n",
    "lines(averages, col=\"green\")\n",
    "legend(1, 1, legend=c(\"R2\", \"R2 adj\", \"R2 CV\"),\n",
    "       col=c(\"blue\", \"red\", \"green\"), lty=1, cex=0.8)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
